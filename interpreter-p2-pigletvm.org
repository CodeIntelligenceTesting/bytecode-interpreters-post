#+OPTIONS: ^:nil num:nil p:nil timestamp:nil todo:nil date:nil creator:nil author:nil toc:nil
#+TITLE: Полет свиньи (или оптимизация интерпретаторов байт-кода)
* TODO [6/7] Статья
** DONE Аннотация

   #+BEGIN_QUOTE
   "No matter how hard you try, you can't make a racehorse out of a pig. You can, however, make a
   faster pig."

   Джеми Завинский (комментарий к исходному коду Емакса)
   #+END_QUOTE

   Широко известен тот факт, что свиньи летают не могут. Не менее популярно мнение о том, что
   интерпретаторы байт-кодов, популярнейшая техника исполнения языков высокого уровня, не поддаются
   ускорению без применения трудоемкой динамической компиляции.

   Во второй части серии статей об интерпретаторах байт-кода я на примере небольшой стековой
   виртуальной машины ПВМ (Поросячья Виртуальная Машина) все же постараюсь показать, что не все
   потеряно для трудолюбивых поросят с амбициями и что в рамках (в основном) стандартного Си вполне
   возможно ускорить работу такого интерпретатора по меньшей мере в полтора раза.

** DONE ПоросенокВМ

   Давайте знакомиться.

   ПоросенокВМ - заурядная стековая машина, основанная на примере стековой машины из первой части
   статьи. Наша свинка знает только один тип данных - 64-битное машинное слово, а все
   (целочисленные) вычисления производит на стеке максимальной глубиной в 256 машинных слов. Кроме
   стека у Поросенка имеется рабочая память длиной в 65536 машинных слов. Результат выполнения
   программы - одно машинное слово - можно либо поместить в специальный регистр результата, либо
   просто вывести в стандартный вывод (stdout).

   Все состояние в ПоросенокВМ хранится в единственной структуре:

   #+BEGIN_SRC cpp
static struct {
    /* Current instruction pointer */
    uint8_t *ip;

    /* Fixed-size stack */
    uint64_t stack[STACK_MAX];
    uint64_t *stack_top;

    /* Operational memory */
    uint64_t memory[MEMORY_SIZE];

    /* A single register containing the result */
    uint64_t result;
} vm;

   #+END_SRC

   Все вышеперечисленное относит ПоросенокВМ к низкоуровневым виртуальным машинах, главные же
   накладные расходы в которых приходятся на обслуживание основного цикла работы программы:

   #+BEGIN_SRC cpp
interpret_result vm_interpret(uint8_t *bytecode)
{
    vm_reset(bytecode);

    for (;;) {
        uint8_t instruction = NEXT_OP();
        switch (instruction) {
        case OP_PUSHI: {
            /* get the argument, push it onto stack */
            uint16_t arg = NEXT_ARG();
            PUSH(arg);
            break;
        }
        case OP_ADD: {
            /* Pop 2 values, add 'em, push the result back to the stack */
            uint64_t arg_right = POP();
            *TOS_PTR() += arg_right;
            break;
        }

        /*
        * ...
        * Lots of other instruction handlers here
        * ...
        */

        case OP_DONE: {
            return SUCCESS;
        }
        default:
            return ERROR_UNKNOWN_OPCODE;
        }
    }

    return ERROR_END_OF_STREAM;
}

    #+END_SRC

   Из кода видно, что на каждый опкод Поросенок должен:

   1. Извлечь опкод из потока инструкций.

   2. Убедиться, что опкод входит в допустимый интервал значений опкодов - эту логику добавляет
      компилятор Си при генерации кода switch-а.

   3. Перейти к телу одной из инструкций.

   4. Извлечь аргументы инструкции со стека, или декодировать аргумент инструкции, размещенный
      непосредственно в байт-коде.

   5. Выполнить, собственно, операцию.

   6. Если есть результат вычисления - поместить его на стек.

   7. Передвинуть указатель текущей инструкции на следующую и перейти в начало цикла.

   Полезная нагрузка здесь только в 6-ом пункте, остальное же - накладные расходы: декодирование или
   извлечение из стека аргументов инструкции (пункт 5), проверка значения опкода (пункт 2),
   многократные прыжки в начало главного цикла (пункты 7) и последующий труднопредсказуемый условный
   переход (пункт 3).

   Словом, у Поросенка явно превышен рекомендованный индекс массы тела, и если мы хотим привести
   нашу свинью в форму, то придется как-то со всеми этим излишествами бороться.

** DONE Свинский язык ассемблера и решето Эратосфена

   Для начала определимся с правилами игры.

   Писать программы для виртуальной машины прямо в Си - моветон, но и делать полноценный язык
   программирования долго, поэтому мы с Поросенком решили ограничиться свинским языком ассемблера.

   Программа, считающая сумму чисел от 1 до 65536, на этом ассемблере выглядит примерно так:

   #+BEGIN_SRC
# sum numbers from 1 to 65535

# init the current sum and the index
PUSHI 1
PUSHI 1
# stack s=1, i=1
STOREI 0
# stack: s=1

# routine: increment the counter, add it to the current sum
incrementandadd:

# check if index is too big
LOADI 0
# stack: s, i
ADDI 1
# stack: s, i+1
DUP
# stack: s, i+1, i+1
GREATER_OR_EQUALI 65535
# stack: s, i+1, 1 or 0
JUMP_IF_TRUE done
# stack: s, i+1
DUP
# stack: s, i+1, i+1
STOREI 0
# stack: s, i+1
ADD
# stack: s+i+1
JUMP incrementandadd

done:
DISCARD
PRINT
DONE
    #+END_SRC

   Не Python, конечно, но все необходимое для поросячьего счастья тут есть: комментарии, метки,
   условные и безусловные переходы по меткам, мнемоники для инструкций и возможность указывать
   непосредственные аргументы инструкций.

   В комплекте с ПоросенокВМ имеются ассемблер и дизассемблер, которые смелые духом и богатые на
   время читатели могут сами опробовать в бою.

   Числа суммируются очень быстро, поэтому для тестов производительности я написал другую
   программу - наивную реализацию алгоритма "решето Эратосфена".

   На самом деле Поросенок и так бегает относительно быстро - его инструкции близки к машинным -,
   поэтому для получения внятных результатов каждый замер я буду делать для ста запусков программы.

   Первая версия нашей неоптимизированной свиньи бегает примерно вот так:

   #+BEGIN_SRC shell
   > ./pigletvm runtimes test/sieve-unoptimized.bin 100 > /dev/null
   PROFILE: switch code finished took 545ms
   #+END_SRC

   Пол секунды! Сравнение, безусловно, нечестное, но тот же алгоритм на Питоне сто пробежек
   делает чуть медленней:

   #+BEGIN_SRC shell
   > python test/sieve.py > /dev/null
   4.66692185402
   #+END_SRC

   Четыре с половиной секунды, или в 9 раз медленней. Надо отдать должное Поросенку - способности у
   него есть! Ну а теперь давайте посмотрим, может ли свинья накачать пресс.

** DONE Упражнение первое: статические суперинструкции

   Первое правило быстрого кода - не делать лишней работы. Второе правило быстрого кода - не делать
   лишней работы никогда. Так какую лишнюю работу делает Поросенок?

   Наблюдение первое: профилирование нашей программы показывает, что есть последовательности
   инструкций, встречающиеся чаще других. Не будем слишком мучать нашу свинью, и ограничимся только
   парами инструкций:

   1. LOADI 0, ADD - положить на стек число из памяти по адресу 0 и прибавить его к числу на вершине стека.

   2. PUSHI 65536, GREATER_OR_EQUAL - положить на стек число и сравнить его с числом, бывшим до того
      на вершине стека, положив результат сравнения (0 или 1) обратно на стек.

   3. PUSHI 1, ADD - положить на стек число и прибавить его к числу, бывшему до того на вершине
      стека, положить результат сложения обратно на стек.

   В ПоросенокВМ чуть больше двадцати инструкций, а для кодирования используется целый байт - 256
   значений. То есть внесение новых инструкций - не проблема. Что мы и проделаем, добавив следующие
   инструкции в код:

   #+BEGIN_SRC cpp
     for (;;) {
         uint8_t instruction = NEXT_OP();
         switch (instruction) {
         /*
          * Other instructions here
          * */
         case OP_LOADADDI: {
             /* get immediate argument as an memory address , add it to value from the address to the top
              * of the stack */
             uint16_t addr = NEXT_ARG();
             uint64_t val = vm.memory[addr];
             *TOS_PTR() += val;
             break;
         }
         case OP_GREATER_OR_EQUALI:{
             /* get the immediate argument, compare it with the value from the address to the top of the stack */
             uint64_t arg_right = NEXT_ARG();
             *TOS_PTR() = PEEK() >= arg_right;
             break;
         }
         case OP_ADDI: {
             /* Add immediate value to the top of the stack */
             uint16_t arg_right = NEXT_ARG();
             *TOS_PTR() += arg_right;
             break;
         }
         /*
          * Other instructions here
          * */
     }

   #+END_SRC

   Ничего сложного. Давайте посмотрим, что из этого получилось:

   #+BEGIN_SRC shell
   > ./pigletvm runtimes test/sieve.bin 100 > /dev/null
   PROFILE: switch code finished took 410ms
   #+END_SRC

   Ого! Кода всего-то на три новых инструкции, а выиграли мы полторы сотни миллисекунд!

   Выигрыш здесь достигается благодаря тому, что Поросенок при выполнении таких инструкций вообще не
   делает лишних движений: поток исполнения не вываливается в главный цикл, ничего лишнего не
   декодирует, аргументы инструкций не проходят через стек.

   Прием это называется /статическими суперинструкциями/, поскольку дополнительные инструкции
   определяются статически, то есть программистом виртуальной машины на этапе разработки. Это
   совершенно честная техника и очень простая техника, ее в той или иной форме используются все
   популярные виртуальные машины языков программирования.

   Главная проблема тут - определить, какие именно инструкции надо объединить. Разные программы
   пользуются разными последовательностями, и узнать эти последовательности можно только на этапе
   запуска конкретного кода.

   Словом, следующим шагом тут могла бы стать динамическая компиляция суперинструкций в контексте
   конкретной программы, то есть /динамические суперинструкции/. В 90-ые и в начале 00-ых это техника
   играла роль примитивной jit-компиляция.

   К рамках же обычного Си это сделать невозможно, и Поросенок совершенно резонно не считает это
   честным соревнованием. К счастью, у меня для него есть пара упражнений получше.

** DONE Упражнение второе: проверка интервала значений опкодов

   Следуя нашим правилам быстро кода еще раз зададимся вечным вопросом: что можно не делать?

   Когда мы знакомились с устройством ПоросенокВМ я перечислял все то, что виртуальная машина делает
   на каждый опкод. И пункт 2 (проверка значения опкода на вхождение в допустимый интервал значений
   switch), тут вызывает больше всего подозрений.

   Давайте присмотримся к тому, как GCC компилирует конструкцию switch:

   1. Строится таблица переходов, т.е. таблица, отображающая значение опкода на адрес исполняющего
      тело инструкции кода.

   2. Вставляется код, который проверяет, входит ли полученный опкод в интервал всех возможных
      значений switch'а, и отправляющий к метке default, если для опкода нет обработчика.

   3. Вставляется код, переходящий к обработчику.

   Но зачем делать проверку интервала значений на каждую инструкцию? Мы считаем, что байт-код у нас
   бывает либо правильный - завершающий исполнение инструкцией OP_DONE, либо неправильный - вышедший
   за пределы байт-кода. Хвост потока опкодов отмечен нулем, а нуль - опкод инструкции OP_ABORT,
   завершающей исполнение байт-кода с ошибкой.

   Выходит, нам вообще не нужна эта проверка! И Поросенок должен уметь доносить эту мысль до
   компилятора. Попробуем немного поправить главный switch:

   #+BEGIN_SRC cpp

   uint8_t instruction = NEXT_OP();
   /* Let the compiler know that opcodes are always between 0 and 31 */
   switch (instruction & 0x1f) {
      /* All the instructions here */
      case 26 ... 0x1f:
          /*Handle the remaining 5 non-existing opcodes*/
          return ERROR_UNKNOWN_OPCODE;
      }
   }

   #+END_SRC

   Зная, что инструкций у нас всего 26 штук, мы накладываем битовую маску (восьмеричное значение
   0x1f это двоичное 0b11111, покрывающее интервал значений от 0 до 31) на опкод, и добавляем
   обработчики на неиспользованные значения в интервале от 26 до 31.

   Битовые инструкции - одни из самых дешевых в архитектуре x86, и уж точно дешевле проблемных
   условных переходов вроде того, что использует проверка на интервал значений. Теоретически мы
   должны выигрывать несколько циклов на каждой исполняемой инструкции, если только компилятор
   поймет наш намек.

   Кстати говоря, способ указания интервала значений в case - не стандартный Си, а расширение GCC.
   Но для наших целей этот код сойдет, тем более что переделать его на несколько обработчиков для
   каждого из ненужных значений несложно.

   Пробуем:

   #+BEGIN_SRC shell

   > ./pigletvm runtimes test/sieve.bin  100 > /dev/null
   PROFILE: switch code finished took 437ms
   PROFILE: switch code (no range check) finished took 383ms

   #+END_SRC

   Еще 50 миллисекунд! Поросенок, ты будто бы в плечах раздался..?

** DONE Упражнение третье: трассы

   Какие еще упражнения могут помочь Поросенку? Самая большая экономия у нас вышла благодаря
   суперинструкциям. А суперинструкции уменьшают число выходов в главный цикл и соответствующих
   накладных расходов.

   Главный цикл и единственный switch - ключевое проблемное место с точки зрения процессоров с
   внеочередным выполнением инструкций. И хотя современные предсказатели ветвлений научились неплохо
   предсказывать даже такие сложные непрямые переходы - "размазывание" мест ветвлений по коду может
   помочь процессору быстро переходить к часто встречающимся вместе инструкциям.

   Другая проблема - побайтовое чтение тела инструкций и непосредственных аргументов из байт-кода.
   Физические машины оперируют 64-битным машинным словом, и не очень любят, когда код оперирует
   меньшими значениями.

   Компиляторы часто оперируют /базовыми блоками/, т.е. последовательностями инструкций без ветвлений
   и меток внутри. Базовый блок начинается либо с начала программы, либо с метки, и заканчивается
   либо концом программы, условным ветвлением или прямым переходом к метке, начинающей другой
   базовому блоку .

   У работы с базовыми блоков много преимуществ, но свинью заинтересовала именно ключевая их
   особенность: инструкции в пределах базового блока выполняются последовательно. Было бы здорово
   как-нибудь выделять эти базовые блоки и исполнять инструкции в них /не теряя времени на выход в
   главный цикл/.

   В наших целях можно даже расширить определение базового блока до /трассы/. Трасса в терминах
   ПоросенокВМ будет включать в себя все последовательно связанные (то есть при помощи безусловного,
   прямого перехода) базовые блоки.

   Кроме последовательного выполнения инструкций неплохо было бы еще заранее декодировать
   непосредственные аргументы инструкций.

   Звучит все это страшно. В конце концов, это напоминает динамическую компиляцию, которые мы решили
   не использовать. Поросенок даже немного засомневался, но на практике все оказалось не так плохо.

   Давайте сначала подумаем, как можно представить отдельную инструкцию, входящую в трассу:

   #+BEGIN_SRC cpp
   struct scode {
       uint64_t arg;
       trace_op_handler *handler;
   };
   #+END_SRC

   Здесь arg - заранее декодированный аргумент инструкции, а handler - функция, выполняющая логику
   самой инструкции.

   Теперь представление каждой трассы:

   #+BEGIN_SRC cpp
   typedef scode trace[MAX_TRACE_LEN];
   #+END_SRC

   То есть трассы это последовательность с-кодов фиксированной максимальной длины. И, наконец, сам
   кеш трасс внутри виртуальной машины выглядит как-то так:

   #+BEGIN_SRC cpp
   trace trace_cache[MAX_CODE_LEN];
   #+END_SRC

   Это просто массив из трассы длиной, соответствующей максимально возможной длине байт-кода. Это,
   конечно, ленивое решение, практически же для экономии памяти имеет смысл использовать
   хэш-таблицу.

   В начале работы интерпретатора первый handler каждой из трасс будет сам себя компилировать:

   #+BEGIN_SRC cpp
    for (size_t trace_i = 0; trace_i < MAX_CODE_LEN; trace_i++ )
        vm_trace.trace_cache[trace_i][0].handler = trace_compile_handler;
   #+END_SRC

   Теперь главный цикл выглядит следующим образом:

   #+BEGIN_SRC cpp
   while(vm_trace.is_running) {
      scode *code = &vm_trace.trace_cache[vm_trace.pc][0];
      code->handler(code);
   }
   #+END_SRC

   Компилирующий обработчик чуть сложнее, и, помимо сборки трассы, начинающейся от текущей
   инструкции, он

   #+BEGIN_SRC cpp
     static void trace_compile_handler(scode *trace_head)
     {
         scode *trace_tail = trace_head;

         /*
          * Trace building here
          */

         /* now, run the chain that has a trace_compile_handler replaced with proper instruction handler
          * function pointer */
         trace_head->handler(trace_head);
     }

   #+END_SRC

   А каждый обработчик инструкции выглядит следующим образом:

   #+BEGIN_SRC cpp
   static void op_add_handler(scode *code)
   {
       uint64_t arg_right = POP();
       *TOS_PTR() += arg_right;

       /*
       * Call the next trace handler
       * */

       /* scodes are located in an array so we can use pointer arithmetic to get the next handler */
       code++;
       code->handler(code);
   }
   #+END_SRC

   Завершает работу каждой трассы специальный обработчик, не делающий никаких вызовов в хвосте
   функции:

   #+BEGIN_SRC cpp
   static void op_done_handler(scode *code)
   {
       (void) code;

       vm_trace.is_running = false;
       vm_trace.error = SUCCESS;
   }
   #+END_SRC

   Все это чуть сложнее, чем простое добавление суперинструкций, но давайте посмотрим, дало ли это
   нам что-нибудь:

   #+BEGIN_SRC shell
   > ./pigletvm runtimes test/sieve.bin  100 > /dev/null
   PROFILE: switch code finished took 427ms
   PROFILE: switch code (no range check) finished took 395ms
   PROFILE: trace code finished took 367ms
   #+END_SRC

   Ура, еще тридцать миллисекунд!

   Как же так? Вместо простых переходов по меткам мы делаем цепочки вызовов обработчиков инструкций.
   Тратим время на вызовы и передачу аргументов, но все равно Поросенок по трассам бегает быстрее
   простого switch с его метками.

   Такой выигрыш по производительности трасс достигается благодаря трем факторам:

   1. Предсказать ветвления, разбросанные по разным местам кода, легко.

   2. Аргументы обработчиков всегда предекодированы в полное машинное слово, и делается это только
      один раз - во время компиляции трассы.

   3. Сами цепочки функции компилятор превращает в единственный вызов первой функции-обработчика,
      что возможно благодаря оптимизации хвостового вызова.

   Думаю, можно подводить итоги свинских тренировок.

** TODO Резюме

   - Альтернативы? "Шитый" код? Регистровая машина? Jit? Другие оптимизации?

   - оптимизация работы со стеком - фиксированная глубина стека на каждой инструкции
